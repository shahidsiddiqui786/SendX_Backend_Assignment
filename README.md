# SendX Backend Assignment

I have Implemented Both Part of the Assignment.
- Basic Version
- Bonus Version



## Basic Version
- Created a API Endpoint `http://localhost:9090/fetch` which will take a url and retry limit and return the response as follows.


***Sample Request***
```
   {
    "uri": "https://google.com",
    "retryLimit": 3
   }
```

***Sample Response***
```
  {
    "id": "51e45731-313a-4fff-adaf-1625d4dfe155",
    "uri": "https://shahid92.netlify.com",
    "sourceUri": "file/51e45731-313a-4fff-adaf-1625d4dfe155.html"
  }
```


### Features
- The Server the takes the uri and fetches the web page.
- Before making any fetch request it checks the url in the cache.
- If found in cache, it returns the response from there directly.
- If the web page is fetched successfully, it downloads it as a file to the local file system.
- If it is not able to fetch the web page, it tries again and again until the retry limit is exhausted.
- On Success, it returns the uri, the ID generated by the "uuid" library, and the downloaded file's local file path.



## Bonus Version
- Created a API Endpoint `http://localhost:9090/fetchall` which will take a list of urls and retry limits and return the response as follows.


***Sample Request***
```
   {
  "urls":[
      {
        "uri": "http://example5.com",
        "retryLimit": 6
      },
      {
        "uri": "http://example4.com",
        "retryLimit": 3
      },
      {
        "uri": "http://example3.com",
        "retryLimit": 12
      },
      {
        "uri": "http://example2.com",
        "retryLimit": 20
      },
      {
        "uri": "http://example1.com",
        "retryLimit": 25
      },
      {
        "uri": "http://example40.com",
        "retryLimit": 50
      }
    ]
}
```

***Sample Response***
```
  {
  "urls": [
    {
      "id": "c85f7be5-d259-4446-9e6a-ca515022264a",
      "uri": "http://example2.com",
      "sourceUri": "file/c85f7be5-d259-4446-9e6a-ca515022264a.html"
    },
    {
      "id": "d155bc20-4591-4364-9619-a1aaac352a9f",
      "uri": "http://example1.com",
      "sourceUri": "file/d155bc20-4591-4364-9619-a1aaac352a9f.html"
    },
    {
      "id": "e8ce9c6f-4760-43f2-86d6-5cb7e52c8141",
      "uri": "http://example3.com",
      "sourceUri": "file/e8ce9c6f-4760-43f2-86d6-5cb7e52c8141.html"
    },
    {
      "id": "b462cfd0-6984-45bd-bff3-9986de85c54f",
      "uri": "http://example4.com",
      "sourceUri": "file/b462cfd0-6984-45bd-bff3-9986de85c54f.html"
    },
    {
      "id": "f1082bba-f0e7-43a2-ad0e-920a2122343d",
      "uri": "http://example5.com",
      "sourceUri": "file/f1082bba-f0e7-43a2-ad0e-920a2122343d.html"
    }
  ],
  "failed": [
    {
      "uri": "http://example40.com",
      "retryLimit": 0
    }
  ]
}
```



### Features
- Similar to the Basic Version it takes a list of urls , and concurrently try to fetch and download the web pages.
- Before making any fetch request it filters and remove those urls from request List which are already present in cache.
- Used `go` keyword ,run the download function concurrently for requested urls and fetch the result.
- If the web page is fetched successfully, it downloads it as a file to the local file system.
- If it is not able to fetch the web page, it tries again and again until the retry limit is exhausted.
- On success, a list of responses is returned that contains the uri, the ID generated by the "uuid" library, and the downloaded file's local file path for each of the correspondingly requested urls. It also contains a failed list, which contains the list of URL requests that were failed.
